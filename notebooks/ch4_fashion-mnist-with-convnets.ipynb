{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras as ks\nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"mnist_fashion = ks.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist_fashion.load_data()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Of the total 70,000 images, 60,000 are used for training and the \nremaining 10,000 for testing. The labels are integer arrays ranging from \n0 to 9. The class names are not a part of the data set. ","metadata":{}},{"cell_type":"code","source":"print(training_images.shape)\nprint(training_labels.shape)\nprint(test_images.shape)\nprint(test_labels.shape)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(60000, 28, 28)\n(60000,)\n(10000, 28, 28)\n(10000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As the pixel values range from 0 to 255, we will scale those values in \nthe range of 0 to 1 before pushing them to the model. We can scale these \nvalues (both for training and test data sets) by dividing the values by 255.","metadata":{}},{"cell_type":"code","source":"training_images = training_images /255.0\ntest_images = test_images / 255.0","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"reshaping the matrix as 28 * 28 * 1","metadata":{}},{"cell_type":"code","source":"training_images = training_images.reshape((60000, 28, 28, 1))\ntest_images = test_images.reshape((10000,28,28,1))\n\nprint(training_images.shape)\nprint(test_images.shape)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(60000, 28, 28, 1)\n(10000, 28, 28, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, let’s build the different layers of the model. We will be using the \nKeras implementation to build the different layers of a CNN. We will keep \nit simple, by having only three layers.\n\nFirst layer—convolutional layer with ReLU activation \nfunction: This layer takes the 2D array (28 × 28 pixels) \nas input. We will take 50 convolutional kernels (filters) \nof shape 3 × 3 pixels. The output of which will be \npassed to a ReLU activation function before being \npassed to the next layer.","metadata":{}},{"cell_type":"code","source":"cnn_model = ks.models.Sequential()\ncnn_model.add(ks.layers.Conv2D(50,(3,3), activation='relu', input_shape=(28,28,1), name='Conv2D_layer'))","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Second layer—pooling layer: This layer takes the 50 \n26 × 26 2D arrays as input and transforms them into \nthe same number (50) of arrays, with dimensions half \nthat of the original (i.e., from 26 × 26 to 13 × 13 pixels)","metadata":{}},{"cell_type":"code","source":"cnn_model.add(ks.layers.MaxPooling2D((2,2), name='Maxpooling_2D'))","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Third layer—fully connected layer: This layer takes the \n50 13 × 13 2D arrays as input and transforms them into \na 1D array of 8450 elements (50 × 13 × 13). These 8450 \ninput elements are passed through a fully connected \nneural network that gives the probability scores for \neach of the 10 output labels (at the output layer).","metadata":{}},{"cell_type":"code","source":"cnn_model.add(ks.layers.Flatten(name='Flatten'))\ncnn_model.add(ks.layers.Dense(50, activation='relu', name='Hidden_layer'))\ncnn_model.add(ks.layers.Dense(10, activation='softmax', name='Output_layer'))","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Lets check the different layers thorugh summary method.","metadata":{}},{"cell_type":"code","source":"cnn_model.summary()","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nConv2D_layer (Conv2D)        (None, 26, 26, 50)        500       \n_________________________________________________________________\nMaxpooling_2D (MaxPooling2D) (None, 13, 13, 50)        0         \n_________________________________________________________________\nFlatten (Flatten)            (None, 8450)              0         \n_________________________________________________________________\nHidden_layer (Dense)         (None, 50)                422550    \n_________________________________________________________________\nOutput_layer (Dense)         (None, 10)                510       \n=================================================================\nTotal params: 423,560\nTrainable params: 423,560\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now we will use an optimization function with the help of the \ncompile method. An Adam optimizer with objective function sparse_\ncategorical_crossentropy, which optimizes for the accuracy metric, can \nbe built as follows:","metadata":{}},{"cell_type":"code","source":"cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Model training:","metadata":{}},{"cell_type":"code","source":"cnn_model.fit(training_images, training_labels, epochs=10)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1875/1875 [==============================] - 24s 13ms/step - loss: 0.5562 - accuracy: 0.8058\nEpoch 2/10\n1875/1875 [==============================] - 23s 12ms/step - loss: 0.2849 - accuracy: 0.8980\nEpoch 3/10\n1875/1875 [==============================] - 23s 12ms/step - loss: 0.2343 - accuracy: 0.9144\nEpoch 4/10\n1875/1875 [==============================] - 23s 12ms/step - loss: 0.2044 - accuracy: 0.9237\nEpoch 5/10\n1875/1875 [==============================] - 24s 13ms/step - loss: 0.1813 - accuracy: 0.9345\nEpoch 6/10\n1875/1875 [==============================] - 23s 13ms/step - loss: 0.1613 - accuracy: 0.9411\nEpoch 7/10\n1875/1875 [==============================] - 23s 12ms/step - loss: 0.1402 - accuracy: 0.9483\nEpoch 8/10\n1875/1875 [==============================] - 23s 12ms/step - loss: 0.1244 - accuracy: 0.9538\nEpoch 9/10\n1875/1875 [==============================] - 23s 12ms/step - loss: 0.1117 - accuracy: 0.9591\nEpoch 10/10\n1875/1875 [==============================] - 22s 12ms/step - loss: 0.0996 - accuracy: 0.9635\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fd6861dddd0>"},"metadata":{}}]},{"cell_type":"markdown","source":"Model evaluation:","metadata":{}},{"cell_type":"code","source":"training_loss, training_accuracy = cnn_model.evaluate(training_images, training_labels)\nprint('Training accuracy {}'.format(round(float(training_accuracy), 2)))","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1875/1875 [==============================] - 8s 4ms/step - loss: 0.0948 - accuracy: 0.9639\nTraining accuracy 0.96\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss,test_accuracy = cnn_model.evaluate(test_images, test_labels)\nprint('Test Accuracy {}'.format(round(float(test_accuracy),2)))","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 2s 5ms/step - loss: 0.2988 - accuracy: 0.9086\nTest Accuracy 0.91\n","output_type":"stream"}]}]}