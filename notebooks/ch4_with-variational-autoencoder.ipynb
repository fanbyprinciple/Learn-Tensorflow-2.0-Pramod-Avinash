{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Variational Autoencoders\n\nLoad the required Python modules","metadata":{}},{"cell_type":"code","source":"!pip install imageio -q","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\ntry:\n    %tensorflow_version 2.x\nexcept Exception:\n    pass\nimport tensorflow as tf\n\nimport os\nimport time\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\nimport PIL\nimport imageio\n\nfrom IPython import display","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Lets load the data set with train test split, nomralisation and binarization","metadata":{}},{"cell_type":"code","source":"(train_data, _), (test_data, _) = tf.keras.datasets.fashion_mnist.load_data()\n","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.reshape(train_data.shape[0], 28, 28, 1).astype('float32')\ntest_data = test_data.reshape(test_data.shape[0], 28, 28, 1).astype('float32')\n# Input Image Normalization to the range of [0,1]\ntrain_data /= 255.\ntest_data /= 255.\n# Binarization of the Normalized Output\ntrain_data[train_data >= .5] = 1.\ntrain_data[train_data < .5] = 0.\ntest_data[test_data >= .5] = 1.\ntest_data[test_data < .5] = 0.","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Abtching and shuffling the dataset","metadata":{}},{"cell_type":"code","source":"TRAIN_SIZE = 60000\nBATCH_SIZE = 50\nTEST_SIZE = 10000\ntrain_batch = tf.data.Dataset.from_tensor_slices(train_data).shuffle(TRAIN_SIZE).batch(BATCH_SIZE)\ntest_batch = tf.data.Dataset.from_tensor_slices(test_data).shuffle(TEST_SIZE).batch(BATCH_SIZE)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Using tf.keras.squential to build the encoder and decoder","metadata":{}},{"cell_type":"code","source":"class CONV_VAE(tf.keras.Model):\n    def __init__(self, latent_dim):\n        super(CONV_VAE, self).__init__()\n        self.latent_vec = latent_vec\n        self.encoder_model = tf.keras.Sequential(\n            [\n              tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n              tf.keras.layers.Conv2D(\n              filters=25, kernel_size=3, strides=(2, 2), activation='relu'),\n              tf.keras.layers.Conv2D(\n                  filters=50, kernel_size=3, strides=(2, 2), activation='relu'),\n              tf.keras.layers.Flatten(),\n              tf.keras.layers.Dense(latent_vec + latent_vec),\n            ]\n        )\n\n        self.decoder_model = tf.keras.Sequential(\n            [\n                tf.keras.layers.InputLayer(input_shape=(latent_vec,)),\n                tf.keras.layers.Dense(units=7*7*25, activation=tf.nn.relu),\n                tf.keras.layers.Reshape(target_shape=(7, 7, 25)),\n                tf.keras.layers.Conv2DTranspose(\n                  filters=50,\n                  kernel_size=3,\n                  strides=(2, 2),\n                  padding=\"SAME\",\n                  activation='relu'),\n                tf.keras.layers.Conv2DTranspose(\n                  filters=25,\n                  kernel_size=3,\n                  strides=(2, 2),\n                  padding=\"SAME\",\n                  activation='relu'),\n                tf.keras.layers.Conv2DTranspose(\n                  filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\"),\n            ]\n        )\n\n    @tf.function\n    def sampling(self, sam=None):\n        if sam is None:\n            sam = tf.random.normal(shape=(50, self.latent_vec))\n        return self.decoder(sam, apply_sigmoid=True)\n\n    def encoder(self, inp):\n        mean, logd = tf.split(self.encoder_model(inp), num_or_size_splits=2, axis=1)\n        return mean, logd\n\n    def reparameterization(self, mean, logd):\n        sam = tf.random.normal(shape=mean.shape)\n        return sam * tf.exp(logd * .5) + mean\n\n    def decoder(self, out, apply_sigmoid=False):\n        logout = self.decoder_model(out)\n        if apply_sigmoid:\n            probabs = tf.sigmoid(logout)\n            return probabs\n\n        return logout","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"building an optimizer function","metadata":{}},{"cell_type":"code","source":"optimizer_func = tf.keras.optimizers.Adam(1e-4)\n\ndef log_normal_prob_dist_func(sample, mean, logd, raxis=1):\n    log2pi = tf.math.log(2. * np.pi)\n    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logd) + logd + log2pi), axis=raxis)\n\n@tf.function\ndef loss_func(model, inp):\n    mean, logd = model.encoder(inp)\n    out = model.reparameterization(mean, logd)\n    log_inp = model.decoder(out)\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=log_inp, labels=inp)\n    logp_inp_out = -tf.reduce_sum(cross_entropy, axis=[1, 2, 3])\n    logp_out = log_normal_prob_dist_func(out, 0., 0.)\n    logq_out_inp = log_normal_prob_dist_func(out, mean, logd)\n    return -tf.reduce_mean(logp_inp_out + logp_out - logq_out_inp)\n\n@tf.function\ndef gradient_func(model, inp, optimizer_func):\n    with tf.GradientTape() as tape:\n        loss = loss_func(model, inp)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer_func.apply_gradients(zip(gradients, model.trainable_variables))","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"epochs = 10 # 100\nlatent_vec = 8\nexamples = 8\n\nrand_vec = tf.random.normal(\n    shape=[examples, latent_vec])\nmodel = CONV_VAE(latent_vec)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(vae_model,epochs, input_data):\n    preds = vae_model.sampling(input_data)\n    fig = plt.figure(figsize=(4,4))\n    \n    for i in range(preds.shape[0]):\n        plt.subplot(4,4,i+1)\n        plt.imshow(preds[i,:,:,0], cmap='gray')\n        plt.axis('off')\n    \n    plt.savefig('img_at_poch{:04d}.png'.format(epochs))\n    plt.show()","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"generate_and_save_images(model,0, rand_vec)\n\nfor epoch in range(1, epochs + 1):\n    start_time = time.time()\n    for x in train_batch:\n        gradient_func(model, x, optimizer_func)\n    end_time = time.time()\n\n    if epoch % 1 == 0:\n        loss = tf.keras.metrics.Mean()\n    for y in test_batch:\n        loss(loss_func(model, y))\n    elbo = -loss.result()\n    display.clear_output(wait=False)\n    print('Epoch no.: {}, Test batch ELBO: {}, '\n          'elapsed time for current epoch {}'.format(epoch, elbo, end_time - start_time))\n    generate_and_save_images(model, epochs, rand_vec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_image(epoch_no):\n    return PIL.Image.open('img_at_epoch{:04d}.png'.format(epoch_no))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(display_image(epochs))\nplt.axis('off')# Display images","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}