{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient_boosting",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub3_wt-mmdNa",
        "outputId": "4108fd23-418b-47bf-b5c9-b438d4714330"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.estimator import LinearClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqan7f2XuLwk",
        "outputId": "d4280e35-b6c9-49a1-b533-44f3248306d8"
      },
      "source": [
        "col_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "\n",
        "target_dimensions = ['Setosa','Versicolor', 'Virginica']\n",
        "\n",
        "training_data_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "\r8192/2194 [================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn6x25BzvX6h",
        "outputId": "e95cd233-7e1e-4cdd-ccce-6a3a899d2f73"
      },
      "source": [
        "test_data_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "\r8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Tue6Lavb40"
      },
      "source": [
        "training = pd.read_csv(training_data_path, names=col_names, header=0)\n",
        "training = training[training['Species'] >= 1]\n",
        "training['Species'] = training['Species'].replace([1,2], [0,1])\n",
        "test = pd.read_csv(test_data_path, names=col_names, header=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "t2fgAsALvxx1",
        "outputId": "1a154927-f648-4ebe-a6ba-706f6634d06c"
      },
      "source": [
        "test = test[test['Species'] >= 1]\n",
        "test['Species'] = test['Species'].replace([1,2],[0,1])\n",
        "training.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "iris_dataset = pd.concat([training, test], axis=0)\n",
        "iris_dataset.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.262000</td>\n",
              "      <td>2.872000</td>\n",
              "      <td>4.906000</td>\n",
              "      <td>1.676000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.662834</td>\n",
              "      <td>0.332751</td>\n",
              "      <td>0.825578</td>\n",
              "      <td>0.424769</td>\n",
              "      <td>0.502519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.900000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.300000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.700000</td>\n",
              "      <td>3.025000</td>\n",
              "      <td>5.525000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       SepalLength  SepalWidth  PetalLength  PetalWidth     Species\n",
              "count   100.000000  100.000000   100.000000  100.000000  100.000000\n",
              "mean      6.262000    2.872000     4.906000    1.676000    0.500000\n",
              "std       0.662834    0.332751     0.825578    0.424769    0.502519\n",
              "min       4.900000    2.000000     3.000000    1.000000    0.000000\n",
              "25%       5.800000    2.700000     4.375000    1.300000    0.000000\n",
              "50%       6.300000    2.900000     4.900000    1.600000    0.500000\n",
              "75%       6.700000    3.025000     5.525000    2.000000    1.000000\n",
              "max       7.900000    3.800000     6.900000    2.500000    1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY7m3CfLwNVk"
      },
      "source": [
        "X_data = iris_dataset[[i for i in iris_dataset.columns if i not in ['Species']]]\n",
        "Y_data = iris_dataset[['Species']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn7EA06Awlxy"
      },
      "source": [
        "training_features, test_features, training_labels, test_labels=train_test_split(X_data, Y_data, test_size=0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jclSZ9gCww-e"
      },
      "source": [
        "def norm(x):\n",
        "  stats = x.describe()\n",
        "  stats = stats.transpose()\n",
        "  return (x - stats['mean'])/stats['std']\n",
        "\n",
        "normed_train_features = norm(training_features)\n",
        "normed_test_features = norm(test_features)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYA1QTsAxC9j"
      },
      "source": [
        "def feed_input(features_dataframe, target_dataframe, num_of_epochs=10, shuffle=True,batch_size=32):\n",
        "  def input_feed_function():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features_dataframe), target_dataframe))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(2000)\n",
        "    dataset = dataset.batch(batch_size).repeat(num_of_epochs)\n",
        "    return dataset\n",
        "  return input_feed_function"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y6HVavM-JVA"
      },
      "source": [
        "train_feed_input = feed_input(normed_train_features, training_labels)\n",
        "train_feed_input_testing = feed_input(normed_train_features, training_labels, num_of_epochs=1, shuffle=False)\n",
        "test_feed_input = feed_input(normed_test_features, \n",
        "test_labels, num_of_epochs=1, shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwXSAF4y-zDq"
      },
      "source": [
        "feature_columns_numeric = [tf.feature_column.numeric_column(m) for m in training_features.columns]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsCqMM1VlmVE",
        "outputId": "e7ae88dd-bd70-4d0e-8ff7-2758b3c93982"
      },
      "source": [
        "from tensorflow.estimator import BoostedTreesClassifier\n",
        "btree_model = BoostedTreesClassifier(feature_columns = feature_columns_numeric, n_batches_per_layer=1)\n",
        "btree_model.train(train_feed_input)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppbfwqtw2\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppbfwqtw2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppbfwqtw2/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.6931472, step = 0\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 17 vs previous value: 17. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 29...\n",
            "INFO:tensorflow:Saving checkpoints for 29 into /tmp/tmppbfwqtw2/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 29...\n",
            "INFO:tensorflow:Loss for final step: 0.048000675.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x7f4a48e663d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iVia9iJmOPQ",
        "outputId": "ea4dbb76-061b-4e2c-b9a7-5cb34e599c9e"
      },
      "source": [
        "train_predictions = btree_model.predict(train_feed_input_testing)\n",
        "test_predictions = btree_model.predict(test_feed_input)\n",
        "train_predictions_series = pd.Series([p['classes'][0].decode(\"utf-8\") for p in train_predictions])\n",
        "test_predictions_series = pd.Series([p['classes'][0].decode(\"utf-8\") for p in test_predictions])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppbfwqtw2/model.ckpt-29\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppbfwqtw2/model.ckpt-29\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7X2BvHPuGmi"
      },
      "source": [
        " def calculate_binary_class_scores(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred.astype('int64'))\n",
        "  precision = precision_score(y_true, y_pred.astype('int64'))\n",
        "  recall = recall_score(y_true, y_pred.astype('int64'))\n",
        "  return accuracy, precision, recall"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giXVEhq0_ybd"
      },
      "source": [
        "train_accuracy_score, train_precision_score, train_recall_score = calculate_binary_class_scores(training_labels, train_predictions_series)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo0F_SoB_44a"
      },
      "source": [
        " test_accuracy_score, test_precision_score, test_recall_score = calculate_binary_class_scores(test_labels, test_predictions_series)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnwJZr-__9bk",
        "outputId": "522e24ed-2096-4cb6-e6d9-7027b405e26b"
      },
      "source": [
        " print('Training Data Accuracy (%) = ', round(train_accuracy_score*100,2))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data Accuracy (%) =  97.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHsu5qcxAArZ",
        "outputId": "9ebcf2e5-cd06-409f-b4b2-312dd5b0b6ca"
      },
      "source": [
        "print('Training Data Precision (%) = ', round(train_precision_score*100,2))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data Precision (%) =  95.45\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}